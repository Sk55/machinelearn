{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸识别实例\n",
    "    它属于生物特征识别技术，是对生物体（一般特指人）本身的生物特征来区分生物体个体。本章主要内容如下： \n",
    "    1）先获取自己的头像，可以通过手机、电脑等拍摄； \n",
    "    2）下载别人的头像，具体网址详见下节； \n",
    "    3）利用dlib、opencv对人脸进行检测； \n",
    "    4）根据检测后的图片，利用卷积神经网络训练模型； \n",
    "    5）把新头像用模型进行识别，看模型是否能认出是你。\n",
    "    \n",
    "### 1.项目概况\n",
    "\n",
    "$~~~~~~~~$1）数据集：总共数据集由两部分组成：他人脸图片集及我自己的部分图片 他人的图片从以下网站获取： 网站地址:http://vis-www.cs.umass.edu/lfw/ 图片集下载:http://vis-www.cs.umass.edu/lfw/lfw.tgz 自己图片可以手机或其它方法拍摄，上传到电脑,输入数据放在： data/face_recog目录下 别人输入图片存放目录 ./data/face_recog/other_faces 我的测试图片目录： ./data/face_recog/test_faces\n",
    "\n",
    "$~~~~~~~~$2）人脸识别 获取数据后，第一件事就对对图片进行处理，即人脸识别，把人脸的范围确定下来，人脸识别有很多方法，这里使用的是dlib来识别人脸部分，当然也可以使用opencv来识别人脸，在实际使用过程中，dlib的识别效果比opencv的好一些。识别处理后的图片存放路径为： data/my_faces(存放预处理我的图片,里面还复制一些图片） data/other_faces（存放预处理别人图片） \n",
    "\n",
    "$~~~~~~~~$3）人脸识别后开始建立模型，训练数据 这里使用卷积神经网络来建立模型，用了3个卷积层（采用了池化、dropout等技术），一个全连接层，分类层、输出层。\n",
    "\n",
    "$~~~~~~~~$4）训练完成后，进行性能评估 \n",
    "\n",
    "$~~~~~~~~$5）用测试数据，验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.主要步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导包\n",
    "import sys \n",
    "import os \n",
    "import cv2 \n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义输入、输出目录，文件解压到当前目录./data/my_faces目录下。\n",
    "#我的头像（可以用手机或电脑等拍摄，尽量清晰、尽量多，越多越好）\n",
    "# 上传到以下input_dir目录下，output_dir为检测以后的头像 \n",
    "input_dir ='./data/face_recog/my_faces'\n",
    "output_dir = './data/my_faces'\n",
    "size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3）判断输出目录是否存在，不存在，则创建。\n",
    "if not os.path.exists(output_dir): \n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4）利用dlib的人脸特征提取器\n",
    "#使用dlib自带的frontal_face_detector作为我们的特征提取器 \n",
    "detector = dlib.get_frontal_face_detector()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Being processed picture 1\n",
      "Being processed picture 2\n",
      "Being processed picture 3\n",
      "Being processed picture 4\n",
      "Being processed picture 5\n",
      "Being processed picture 6\n",
      "Being processed picture 6\n",
      "Being processed picture 7\n",
      "Being processed picture 8\n",
      "Being processed picture 8\n",
      "Being processed picture 9\n",
      "Being processed picture 10\n",
      "Being processed picture 11\n",
      "Being processed picture 12\n",
      "Being processed picture 13\n",
      "Being processed picture 14\n",
      "Being processed picture 15\n",
      "Being processed picture 16\n",
      "Being processed picture 17\n",
      "Being processed picture 18\n",
      "Being processed picture 19\n",
      "Being processed picture 20\n",
      "Being processed picture 21\n",
      "Being processed picture 22\n",
      "Being processed picture 23\n",
      "Being processed picture 24\n",
      "Being processed picture 25\n",
      "Being processed picture 26\n",
      "Being processed picture 27\n",
      "Being processed picture 27\n",
      "Being processed picture 28\n",
      "Being processed picture 28\n",
      "Being processed picture 28\n",
      "Being processed picture 28\n",
      "Being processed picture 29\n",
      "Being processed picture 30\n",
      "Being processed picture 31\n",
      "Being processed picture 32\n",
      "Being processed picture 32\n",
      "Being processed picture 33\n",
      "Being processed picture 33\n",
      "Being processed picture 34\n",
      "Being processed picture 35\n",
      "Being processed picture 36\n",
      "Being processed picture 37\n",
      "Being processed picture 38\n",
      "Being processed picture 39\n",
      "Being processed picture 40\n",
      "Being processed picture 40\n",
      "Being processed picture 40\n",
      "Being processed picture 40\n",
      "Being processed picture 41\n",
      "Being processed picture 42\n",
      "Being processed picture 43\n",
      "Being processed picture 43\n",
      "Being processed picture 43\n",
      "Being processed picture 43\n",
      "Being processed picture 44\n",
      "Being processed picture 44\n",
      "Being processed picture 45\n",
      "Being processed picture 46\n",
      "Being processed picture 47\n",
      "Being processed picture 48\n",
      "Being processed picture 49\n",
      "Being processed picture 50\n",
      "Being processed picture 51\n",
      "Being processed picture 52\n",
      "Being processed picture 53\n",
      "Being processed picture 54\n",
      "Being processed picture 55\n",
      "Being processed picture 56\n",
      "Being processed picture 57\n",
      "Being processed picture 58\n",
      "Being processed picture 59\n",
      "Being processed picture 60\n",
      "Being processed picture 61\n",
      "Being processed picture 62\n",
      "Being processed picture 63\n",
      "Being processed picture 64\n",
      "Being processed picture 65\n",
      "Being processed picture 66\n",
      "Being processed picture 67\n",
      "Being processed picture 68\n",
      "Being processed picture 68\n",
      "Being processed picture 69\n",
      "Being processed picture 70\n",
      "Being processed picture 71\n",
      "Being processed picture 72\n",
      "Being processed picture 73\n",
      "Being processed picture 74\n",
      "Being processed picture 75\n",
      "Being processed picture 76\n",
      "Being processed picture 77\n",
      "Being processed picture 78\n",
      "Being processed picture 79\n",
      "Being processed picture 80\n",
      "Being processed picture 81\n",
      "Being processed picture 82\n",
      "Being processed picture 83\n",
      "Being processed picture 84\n",
      "Being processed picture 85\n",
      "Being processed picture 86\n",
      "Being processed picture 87\n",
      "Being processed picture 88\n",
      "Being processed picture 89\n",
      "Being processed picture 89\n",
      "Being processed picture 90\n",
      "Being processed picture 91\n",
      "Being processed picture 92\n",
      "Being processed picture 93\n",
      "Being processed picture 94\n",
      "Being processed picture 95\n",
      "Being processed picture 96\n",
      "Being processed picture 97\n",
      "Being processed picture 98\n",
      "Being processed picture 99\n",
      "Being processed picture 100\n",
      "Being processed picture 101\n",
      "Being processed picture 102\n",
      "Being processed picture 103\n",
      "Being processed picture 104\n",
      "Being processed picture 105\n",
      "Being processed picture 106\n",
      "Being processed picture 107\n",
      "Being processed picture 108\n",
      "Being processed picture 109\n",
      "Being processed picture 110\n",
      "Being processed picture 111\n",
      "Being processed picture 112\n",
      "Being processed picture 113\n",
      "Being processed picture 114\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "index = 1 \n",
    "for (path, dirnames, filenames) in os.walk(input_dir):\n",
    "\n",
    "    \n",
    "    for filename in filenames: \n",
    "        if filename.endswith('.jpg'): \n",
    "            print('Being processed picture %s' % index) \n",
    "            img_path = path+'/'+filename \n",
    "            # 从文件读取图片 \n",
    "            img = cv2.imread(img_path) \n",
    "            # 转为灰度图片 \n",
    "            \n",
    "            \n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "            # 使用detector进行人脸检测 dets为返回的结果 \n",
    "            dets = detector(gray_img, 1)\n",
    "            \n",
    "            #使用enumerate 函数遍历序列中的元素以及它们的下标\n",
    "            #下标i即为人脸序号 \n",
    "            #left：人脸左边距离图片左边界的距离 ；\n",
    "            #right：人脸右边距离图片左边界的距离 \n",
    "            #top：人脸上边距离图片上边界的距离 ；\n",
    "            #bottom：人脸下边距离图片上边界的距离\n",
    "            for i, d in enumerate(dets): \n",
    "                x1 = d.top() if d.top() > 0 else 0 \n",
    "                y1 = d.bottom() if d.bottom() > 0 else 0  #大于0 表示所取得特征在相框内，那么就取此特征，如果小于0，则去相框边缘\n",
    "                x2 = d.left() if d.left() > 0 else 0 \n",
    "                y2 = d.right() if d.right() > 0 else 0 \n",
    "                # img[y:y+h,x:x+w] \n",
    "                face = img[x1:y1,x2:y2] \n",
    "                # 调整图片的尺寸 \n",
    "                face = cv2.resize(face, (size,size))  #把获取的相片转换为64乘以64像素的，便于分析\n",
    "                cv2.imshow('image',face) \n",
    "                # 保存图片 \n",
    "                \n",
    "                cv2.imwrite(output_dir+'/'+str(index)+'.jpg', face)\n",
    "                index += 1 \n",
    "            #不断刷新图像，频率时间为30ms \n",
    "            key = cv2.waitKey(30) & 0xff \n",
    "            if key == 27: \n",
    "                sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#别人图片输入输出目录 \n",
    "input_dir = '.data/face_recog/other_faces' \n",
    "output_dir = './data/other_faces' \n",
    "size = 64\n",
    "# 判断输出目录是否存在，不存在，则创建。\n",
    "if not os.path.exists(output_dir): \n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "    \n",
    "    \n",
    "# detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "index = 1\n",
    "for (path, dirnames, filenames) in os.walk(input_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.jpg'):\n",
    "            print('Being processed picture %s' % index)\n",
    "            img_path = path+'/'+filename\n",
    "            img = cv2.imread(img_path)      # 读取图片,转为灰度图片\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "            dets = detector(gray_img,1)    # 使用 detector 进行人脸检测dets为返回的结果\n",
    "            \"\"\"\n",
    "                下标 i 即为人脸序号\n",
    "                left：人脸左边距离图片左边界的距离 ；right：人脸右边距离图片左边界的距离\n",
    "                top：人脸上边距离图片上边界的距离 ；bottom：人脸下边距离图片上边界的距离\n",
    "            \"\"\"\n",
    "            for i, d in enumerate(dets):\n",
    "                x1 = d.top() if d.top() > 0 else 0\n",
    "                y1 = d.bottom() if d.bottom() > 0 else 0\n",
    "                x2 = d.left() if d.left() > 0 else 0\n",
    "                y2 = d.right() if d.right() > 0 else 0\n",
    "                \n",
    "                face = img[x1:y1,x2:y2]               # img[y:y+h,x:x+w]\n",
    "                face = cv2.resize(face, (size,size))  # 调整图片的尺寸\n",
    "                cv2.imshow('image',face)\n",
    "                # 保存图片\n",
    "                cv2.imwrite(output_dir+'/'+str(index)+'.jpg', face)\n",
    "                index += 1\n",
    "            key = cv2.waitKey(30) & 0xff        #不断刷新图像，频率时间为 30ms\n",
    "            if key == 27:\n",
    "                sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\haha\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import os \n",
    "import random \n",
    "import sys \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_faces_path = './data/my_faces' \n",
    "other_faces_path = './data/other_faces'\n",
    "size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整或规范图片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)调整或规范图片大小 \n",
    "\n",
    "imgs = []\n",
    "labs = []\n",
    "\n",
    "#重新创建图形变量 \n",
    "tf.reset_default_graph() \n",
    "#获取需要填充图片的大小 \n",
    "\n",
    "#得到的是比例缩放的规格\n",
    "def getPaddingSize(img): \n",
    "    h, w, _ = img.shape\n",
    "    top, bottom, left, right = (0,0,0,0) \n",
    "    longest = max(h, w)\n",
    "    if w < longest: \n",
    "        tmp = longest - w\n",
    "        # //表示整除符号 \n",
    "        left = tmp // 2 \n",
    "        right = tmp - left \n",
    "    elif h < longest: \n",
    "        tmp = longest - h \n",
    "        top = tmp // 2 \n",
    "        bottom = tmp - top \n",
    "    else: \n",
    "        pass \n",
    "    return top, bottom, left, right \n",
    "#返回的是特征提取框的大小，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取测试图片及归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363, 64, 64, 3)\n",
      "train size:363, test size:20\n"
     ]
    }
   ],
   "source": [
    "# 4)读取测试图片\n",
    "def readData(path , h=size, w=size): \n",
    "    for filename in os.listdir(path): \n",
    "        if filename.endswith('.jpg'): \n",
    "            filename = path + '/' + filename \n",
    "\n",
    "            img = cv2.imread(filename)  \n",
    "\n",
    "            top,bottom,left,right = getPaddingSize(img) \n",
    "            # 将图片放大， 扩充图片边缘部分 \n",
    "            img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0,0,0]) \n",
    "            img = cv2.resize(img, (h, w)) \n",
    "\n",
    "            imgs.append(img)           #图片集\n",
    "            labs.append(path)          #路径文件标签\n",
    "            \n",
    "readData(my_faces_path) \n",
    "readData(other_faces_path) \n",
    "\n",
    "# 将图片数据与标签转换成数组 \n",
    "imgs = np.array(imgs)\n",
    "\n",
    "labs = np.array([[0,1] if lab == my_faces_path else [1,0] for lab in labs])\n",
    "# 随机划分测试集与训练集 t\n",
    "train_x,test_x,train_y,test_y = train_test_split(\n",
    "                                                imgs, labs, \n",
    "                                                test_size=0.05,\n",
    "                                                random_state=random.randint(0,100)\n",
    ") \n",
    "# 参数：图片数据的总数，图片的高、宽、通道 \n",
    "train_x = train_x.reshape(train_x.shape[0], size, size, 3) \n",
    "test_x = test_x.reshape(test_x.shape[0], size, size, 3) \n",
    "print(train_x.shape)\n",
    "# 将数据转换成小于1的数 （归一化）\n",
    "train_x = train_x.astype('float32')/255.0 \n",
    "test_x = test_x.astype('float32')/255.0 \n",
    "print('train size:%s, test size:%s' % (len(train_x), len(test_x))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置批梯度下降的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 图片块，每次取20张图片 \n",
    "batch_size = 20\n",
    "num_batch = len(train_x) // batch_size\n",
    "num_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络层编写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)定义变量及神经网络层\n",
    "x = tf.placeholder(tf.float32, [None, size, size, 3]) \n",
    "y_ = tf.placeholder(tf.float32, [None, 2]) \n",
    "keep_prob_5 = tf.placeholder(tf.float32) 　　#保留百分之５的连接(后面的参数设置)\n",
    "keep_prob_75 = tf.placeholder(tf.float32) 　　#保留百分之７５的连接\n",
    "def weightVariable(shape):   #定义一个初始化权重参数\n",
    "    init = tf.random_normal(shape, stddev=0.01)  #标准差为0.01\n",
    "    return tf.Variable(init) \n",
    "\n",
    "def biasVariable(shape):    #定义一个偏值项\n",
    "    init = tf.random_normal(shape) \n",
    "    return tf.Variable(init) \n",
    "\n",
    "def conv2d(x, W):   #定义一个卷基层\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')    # 卷积核用1*1的\n",
    "\n",
    "def maxPool(x): #定义一个最大池化层函数\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def dropout(x, keep):   \n",
    "    return tf.nn.dropout(x, keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6)定义卷积神经网络框架\n",
    "def cnnLayer(): \n",
    "    # 第一层 \n",
    "    W1 = weightVariable([3,3,3,32]) \n",
    "    # 卷积核大小(3,3)， 输入通道(3)， 输出通道(32) \n",
    "    b1 = biasVariable([32])   #32个输出就是32个偏值\n",
    "    # 卷积 \n",
    "    conv1 = tf.nn.relu(conv2d(x, W1) + b1)   #relu激活函数\n",
    "    # 最大池化 \n",
    "    pool1 = maxPool(conv1) \n",
    "    # 减少过拟合，随机让某些权重不更新 \n",
    "    drop1 = dropout(pool1, keep_prob_5) \n",
    "    \n",
    "    \n",
    "    # 第二层 \n",
    "    W2 = weightVariable([3,3,32,64])\n",
    "    b2 = biasVariable([64]) \n",
    "    conv2 = tf.nn.relu(conv2d(drop1, W2) + b2) \n",
    "    pool2 = maxPool(conv2) \n",
    "    drop2 = dropout(pool2, keep_prob_5) \n",
    "    \n",
    "    \n",
    "    # 第三层 \n",
    "    W3 = weightVariable([3,3,64,64]) \n",
    "    b3 = biasVariable([64]) \n",
    "    conv3 = tf.nn.relu(conv2d(drop2, W3) + b3) \n",
    "    pool3 = maxPool(conv3) \n",
    "    drop3 = dropout(pool3, keep_prob_5) \n",
    "    \n",
    "    # 全连接层 \n",
    "    Wf = weightVariable([8*16*32, 512]) \n",
    "    bf = biasVariable([512]) \n",
    "    drop3_flat = tf.reshape(drop3, [-1, 8*16*32]) \n",
    "    dense = tf.nn.relu(tf.matmul(drop3_flat, Wf) + bf) \n",
    "    dropf = dropout(dense, keep_prob_75)\n",
    "\n",
    "    #输出层 \n",
    "    Wout = weightVariable([512,2]) \n",
    "    bout = weightVariable([2]) \n",
    "    #out = tf.matmul(dropf, Wout) + bout \n",
    "    out = tf.add(tf.matmul(dropf, Wout), bout) #构成新的数组组成的图片\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-0245a04aa9c4>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "batch_data0 , loss is 0.7021134495735168\n",
      "batch_data 0step,accuracy is 0.8500000238418579\n",
      "batch_data1 , loss is 33.35606002807617\n",
      "batch_data2 , loss is 3.0203349590301514\n",
      "batch_data3 , loss is 0.6276081800460815\n",
      "batch_data4 , loss is 0.8774675130844116\n",
      "batch_data5 , loss is 1.1009132862091064\n",
      "batch_data6 , loss is 0.7983958721160889\n",
      "batch_data7 , loss is 0.5887211561203003\n",
      "batch_data8 , loss is 1.0601348876953125\n",
      "batch_data9 , loss is 0.5590571165084839\n",
      "batch_data10 , loss is 0.6465830206871033\n",
      "batch_data11 , loss is 0.733173131942749\n",
      "batch_data12 , loss is 0.5917478799819946\n",
      "batch_data13 , loss is 0.745909571647644\n",
      "batch_data14 , loss is 0.41689547896385193\n",
      "batch_data15 , loss is 0.6435226202011108\n",
      "batch_data16 , loss is 0.3732021749019623\n",
      "batch_data17 , loss is 0.3862202763557434\n",
      "batch_data18 , loss is 0.34003615379333496\n",
      "batch_data19 , loss is 0.2745984196662903\n",
      "batch_data20 , loss is 0.3030945062637329\n",
      "batch_data21 , loss is 0.3654784858226776\n",
      "batch_data22 , loss is 0.10442479699850082\n",
      "batch_data23 , loss is 0.2446000576019287\n",
      "batch_data24 , loss is 0.1766614317893982\n",
      "batch_data25 , loss is 0.4709760546684265\n",
      "batch_data26 , loss is 0.3506103754043579\n",
      "batch_data27 , loss is 0.19788141548633575\n",
      "batch_data28 , loss is 0.14689314365386963\n",
      "batch_data29 , loss is 0.4121829867362976\n",
      "batch_data30 , loss is 0.2493687868118286\n",
      "batch_data31 , loss is 0.17116573452949524\n",
      "batch_data32 , loss is 0.07135980576276779\n",
      "batch_data33 , loss is 0.385349839925766\n",
      "batch_data34 , loss is 0.46367472410202026\n",
      "batch_data35 , loss is 0.4833138585090637\n",
      "batch_data36 , loss is 0.26569733023643494\n",
      "batch_data37 , loss is 0.2481127232313156\n",
      "batch_data38 , loss is 0.2705272138118744\n",
      "batch_data39 , loss is 0.2106422483921051\n",
      "batch_data40 , loss is 0.09656412899494171\n",
      "batch_data 40step,accuracy is 0.8500000238418579\n",
      "batch_data41 , loss is 0.20167043805122375\n",
      "batch_data42 , loss is 0.46767061948776245\n",
      "batch_data43 , loss is 0.6392839550971985\n",
      "batch_data44 , loss is 0.6960883140563965\n",
      "batch_data45 , loss is 0.07426974177360535\n",
      "batch_data46 , loss is 0.08865847438573837\n",
      "batch_data47 , loss is 0.0206801388412714\n",
      "batch_data48 , loss is 0.16385985910892487\n",
      "batch_data49 , loss is 0.1088770180940628\n",
      "batch_data50 , loss is 0.2004152089357376\n",
      "batch_data51 , loss is 0.6046385169029236\n",
      "batch_data52 , loss is 0.27347391843795776\n",
      "batch_data53 , loss is 0.2823622226715088\n",
      "batch_data54 , loss is 0.330314576625824\n",
      "batch_data55 , loss is 0.37830686569213867\n",
      "batch_data56 , loss is 0.32413142919540405\n",
      "batch_data57 , loss is 0.2589644491672516\n",
      "batch_data58 , loss is 0.1680033653974533\n",
      "batch_data59 , loss is 0.3641555607318878\n",
      "batch_data60 , loss is 0.10435795783996582\n",
      "batch_data61 , loss is 0.3253507614135742\n",
      "batch_data62 , loss is 0.15954914689064026\n",
      "batch_data63 , loss is 0.19079698622226715\n",
      "batch_data64 , loss is 0.024337714537978172\n",
      "batch_data65 , loss is 0.07560364156961441\n",
      "batch_data66 , loss is 0.525032639503479\n",
      "batch_data67 , loss is 0.15824711322784424\n",
      "batch_data68 , loss is 0.6688782572746277\n",
      "batch_data69 , loss is 0.3953130841255188\n",
      "batch_data70 , loss is 0.2762663960456848\n",
      "batch_data71 , loss is 0.36704233288764954\n",
      "batch_data72 , loss is 0.3742794990539551\n",
      "batch_data73 , loss is 0.03278350830078125\n",
      "batch_data74 , loss is 0.18734124302864075\n",
      "batch_data75 , loss is 0.1615523099899292\n",
      "batch_data76 , loss is 0.19003763794898987\n",
      "batch_data77 , loss is 0.37558719515800476\n",
      "batch_data78 , loss is 0.168507918715477\n",
      "batch_data79 , loss is 0.29331332445144653\n",
      "batch_data80 , loss is 0.14376261830329895\n",
      "batch_data 80step,accuracy is 0.8999999761581421\n",
      "batch_data81 , loss is 0.40829506516456604\n",
      "batch_data82 , loss is 0.09252509474754333\n",
      "batch_data83 , loss is 0.09318532049655914\n",
      "batch_data84 , loss is 0.20254845917224884\n",
      "batch_data85 , loss is 0.10766498744487762\n",
      "batch_data86 , loss is 0.34046614170074463\n",
      "batch_data87 , loss is 0.5151743292808533\n",
      "batch_data88 , loss is 0.27607014775276184\n",
      "batch_data89 , loss is 0.12339508533477783\n",
      "batch_data90 , loss is 0.10513267666101456\n",
      "batch_data91 , loss is 0.29053422808647156\n",
      "batch_data92 , loss is 0.07711271941661835\n",
      "batch_data93 , loss is 0.10170306265354156\n",
      "batch_data94 , loss is 0.10379441827535629\n",
      "batch_data95 , loss is 0.4310893416404724\n",
      "batch_data96 , loss is 0.25404390692710876\n",
      "batch_data97 , loss is 0.18920931220054626\n",
      "batch_data98 , loss is 0.2481197565793991\n",
      "batch_data99 , loss is 0.27659741044044495\n",
      "batch_data100 , loss is 0.05097854137420654\n",
      "batch_data101 , loss is 0.0648055300116539\n",
      "batch_data102 , loss is 0.07637724280357361\n",
      "batch_data103 , loss is 0.15224382281303406\n",
      "batch_data104 , loss is 0.15082906186580658\n",
      "batch_data105 , loss is 0.11236782371997833\n",
      "batch_data106 , loss is 0.4306204915046692\n",
      "batch_data107 , loss is 0.1327517330646515\n",
      "batch_data108 , loss is 0.125926211476326\n",
      "batch_data109 , loss is 0.12627243995666504\n",
      "batch_data110 , loss is 0.2005496770143509\n",
      "batch_data111 , loss is 0.07981691509485245\n",
      "batch_data112 , loss is 0.2580893933773041\n",
      "batch_data113 , loss is 0.15012569725513458\n",
      "batch_data114 , loss is 0.03630949929356575\n",
      "batch_data115 , loss is 0.10391546785831451\n",
      "batch_data116 , loss is 0.08519814163446426\n",
      "batch_data117 , loss is 0.10432128608226776\n",
      "batch_data118 , loss is 0.1512773483991623\n",
      "batch_data119 , loss is 0.4968706965446472\n",
      "batch_data120 , loss is 0.11412600427865982\n",
      "batch_data 120step,accuracy is 0.800000011920929\n",
      "batch_data121 , loss is 0.33664077520370483\n",
      "batch_data122 , loss is 0.08127634227275848\n",
      "batch_data123 , loss is 0.33141034841537476\n",
      "batch_data124 , loss is 0.4972161650657654\n",
      "batch_data125 , loss is 0.18559694290161133\n",
      "batch_data126 , loss is 0.14276781678199768\n",
      "batch_data127 , loss is 0.2802981734275818\n",
      "batch_data128 , loss is 0.37771621346473694\n",
      "batch_data129 , loss is 0.0627714991569519\n",
      "batch_data130 , loss is 0.1487586945295334\n",
      "batch_data131 , loss is 0.2966783344745636\n",
      "batch_data132 , loss is 0.06486918032169342\n",
      "batch_data133 , loss is 0.4155551791191101\n",
      "batch_data134 , loss is 0.10371808707714081\n",
      "batch_data135 , loss is 0.16366927325725555\n",
      "batch_data136 , loss is 0.05818932130932808\n",
      "batch_data137 , loss is 0.11448540538549423\n",
      "batch_data138 , loss is 0.0678258165717125\n",
      "batch_data139 , loss is 0.2755405008792877\n",
      "batch_data140 , loss is 0.32766371965408325\n",
      "batch_data141 , loss is 0.4525962769985199\n",
      "batch_data142 , loss is 0.05998266488313675\n",
      "batch_data143 , loss is 0.32276061177253723\n",
      "batch_data144 , loss is 0.20193438231945038\n",
      "batch_data145 , loss is 0.054810453206300735\n",
      "batch_data146 , loss is 0.26276057958602905\n",
      "batch_data147 , loss is 0.08876682817935944\n",
      "batch_data148 , loss is 0.034279774874448776\n",
      "batch_data149 , loss is 0.3496769070625305\n",
      "batch_data150 , loss is 0.018190231174230576\n",
      "batch_data151 , loss is 0.1726388782262802\n",
      "batch_data152 , loss is 0.13494226336479187\n",
      "batch_data153 , loss is 0.4040735363960266\n",
      "batch_data154 , loss is 0.09262781590223312\n",
      "batch_data155 , loss is 0.08132956922054291\n",
      "batch_data156 , loss is 0.19759109616279602\n",
      "batch_data157 , loss is 0.1538136899471283\n",
      "batch_data158 , loss is 0.41423577070236206\n",
      "batch_data159 , loss is 0.25839102268218994\n",
      "batch_data160 , loss is 0.09371112287044525\n",
      "batch_data 160step,accuracy is 0.949999988079071\n",
      "batch_data161 , loss is 0.15491506457328796\n",
      "batch_data162 , loss is 0.044055718928575516\n",
      "batch_data163 , loss is 0.12585844099521637\n",
      "batch_data164 , loss is 0.08975150436162949\n",
      "batch_data165 , loss is 0.10191402584314346\n",
      "batch_data166 , loss is 0.008810210973024368\n",
      "batch_data167 , loss is 0.0653199627995491\n",
      "batch_data168 , loss is 0.04845527186989784\n",
      "batch_data169 , loss is 0.1321640908718109\n",
      "batch_data170 , loss is 0.047515325248241425\n",
      "batch_data171 , loss is 0.19434818625450134\n",
      "batch_data172 , loss is 0.1102534756064415\n",
      "batch_data173 , loss is 0.08926013857126236\n",
      "batch_data174 , loss is 0.06088162213563919\n",
      "batch_data175 , loss is 0.06072411686182022\n",
      "batch_data176 , loss is 0.05435947701334953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_data177 , loss is 0.011008042842149734\n",
      "batch_data178 , loss is 0.2594223916530609\n",
      "batch_data179 , loss is 0.02874944545328617\n"
     ]
    }
   ],
   "source": [
    "def cnnTrain():\n",
    "    out = cnnLayer()\n",
    "    cross_entropy =tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y_))  #最小化代价函数，使用SOFTMAX进行概率分类\n",
    "    train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)   #自适应Adam，学习率为0.01\n",
    "    \n",
    "    # 比较标签是否相等，再求的所有数的平均值，tf.cast(强制转换类型)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, 1),\n",
    "                                               tf.argmax(y_,1)), tf.float32))\n",
    "    \n",
    "    # 将 loss 与 accuracy 保存以供 tensorboard 使用\n",
    "    tf.summary.scalar('loss', cross_entropy)  \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver()             # 数据保存器的初始化\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())  #初始化模型参数\n",
    "        '''\n",
    "        global_variables_initializer 返回一个用来初始化 计算图中 所有global variable的 op。 \n",
    "            函数中调用了 variable_initializer() 和 global_variables()\n",
    "        global_variables() 返回一个 Variable list ，里面保存的是 gloabal variables。\n",
    "        variable_initializer() 将 Variable list 中的所有 Variable 取出来，将其 variable.initializer 属性做成一个 op group。\n",
    "        然后看 Variable 类的源码可以发现， variable.initializer 就是一个 assign op。\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        summary_writer = tf.summary.FileWriter('./tmp',graph=tf.get_default_graph()) #写入\n",
    "    \n",
    "        for n in range(10):\n",
    "            for i in range(num_batch):             # 每次取 128(batch_size)张图片,num_batch=18\n",
    "                batch_x = train_x[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "                # 喂数据：开始训练数据，同时训练三个变量，返回三个数据  #################################\n",
    "                _,loss,summary = sess.run([train_step, cross_entropy,merged_summary_op],\n",
    "                                          feed_dict={x:batch_x,y_:batch_y,keep_prob_5:0.5,keep_prob_75:0.75})\n",
    "                summary_writer.add_summary(summary, 1)\n",
    "                print(\"batch_data{} , loss is {}\".format(n*num_batch+i, loss))   # 打印损失 \n",
    "        \n",
    "                if (n*num_batch+i) % 40 == 0:                                    # 获取测试数据的准确率\n",
    "\n",
    "                    acc = accuracy.eval({x:test_x, y_:test_y, keep_prob_5:0.5,keep_prob_75:0.75})\n",
    "                    print(\"batch_data {}step,accuracy is {}\".format(n*num_batch+i, acc))\n",
    "\n",
    "                    if acc > 0.8 and n > 2:          # 由于数据不多，这里设为准确率大于 0.80 时保存并退出\n",
    "                        #saver.save(sess,'./train_face_model/train_faces.model',global_step=n*num_batch+i)\n",
    "                        saver.save(sess,'./train_face_model/train_faces.model')\n",
    "                        #print('accuracy less 0.80, exited!')\n",
    "cnnTrain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 测试模型\n",
    "用训练得到的模型，测试我新的头像，看她是否认识我。 首先，把我的4张测试照片放在./data/face_recog/test_faces目录，然后，让模型来识别这些照片是否是我。|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_face_model/train_faces.model\n",
      "Being processed picture 1\n",
      "Is this my face? False\n",
      "Being processed picture 2\n",
      "Is this my face? True\n",
      "Being processed picture 3\n",
      "Is this my face? False\n",
      "Being processed picture 4\n",
      "Is this my face? False\n",
      "Being processed picture 5\n",
      "Is this my face? True\n",
      "Being processed picture 6\n",
      "Is this my face? False\n",
      "Being processed picture 7\n",
      "Is this my face? False\n",
      "Being processed picture 8\n",
      "Is this my face? False\n",
      "Being processed picture 9\n",
      "Is this my face? False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "input_dir='./data/test_faces'\n",
    "index=1\n",
    "output = cnnLayer()\n",
    "predict = tf.argmax(output, 1)\n",
    "\n",
    "#先加载 meta graph 并恢复权重变量\n",
    "saver = tf.train.import_meta_graph('./train_face_model/train_faces.model.meta')\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./train_face_model/'))\n",
    "\n",
    "def is_my_face(image):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    res = sess.run(predict, feed_dict={x: [image/255.0], keep_prob_5:1.0,keep_prob_75: 1.0}) \n",
    "\n",
    "    if res[0] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#使用 dlib 自带的 frontal_face_detector 作为我们的特征提取器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "#cam = cv2.VideoCapture(0)\n",
    "for (path, dirnames, filenames) in os.walk(input_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.jpg'):\n",
    "            print('Being processed picture %s' % index)\n",
    "            index+=1\n",
    "            img_path = path+'/'+filename\n",
    "            # 从文件读取图片\n",
    "            img = cv2.imread(img_path)\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #转灰度图\n",
    "            dets = detector(gray_image, 1)\n",
    "            if not len(dets):\n",
    "                print('Can`t get face.')\n",
    "                cv2.imshow('img', img)\n",
    "                key = cv2.waitKey(30) & 0xff\n",
    "                if key == 27:\n",
    "                    sys.exit(0)\n",
    "            for i, d in enumerate(dets):\n",
    "                x1 = d.top() if d.top() > 0 else 0\n",
    "                y1 = d.bottom() if d.bottom() > 0 else 0\n",
    "                x2 = d.left() if d.left() > 0 else 0\n",
    "                y2 = d.right() if d.right() > 0 else 0\n",
    "                face = img[x1:y1,x2:y2]\n",
    "                # 调整图片的尺寸\n",
    "                face = cv2.resize(face, (size,size))\n",
    "                print('Is this my face? %s' % is_my_face(face))\n",
    "    \n",
    "                cv2.rectangle(img, (x2,x1),(y2,y1), (255,0,0),3)\n",
    "                cv2.imshow('image',img)\n",
    "                key = cv2.waitKey(30) & 0xff\n",
    "                if key == 27:\n",
    "                    sys.exit(0)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论\n",
    "    训练模型，准确度高达95%左右，但是预测时，准确率非常低下，表明，模型处于过拟合，该模型效果不好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
